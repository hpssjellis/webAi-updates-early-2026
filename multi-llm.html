<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Janus-Pro Multimodal Lab</title>
    <style>
        :root { --primary: #00d2ff; --bg: #0f172a; --card: #1e293b; }
        body { background: var(--bg); color: #f8fafc; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; display: flex; flex-direction: column; align-items: center; padding: 20px; }
        .container { width: 100%; max-width: 850px; }
        .card { background: var(--card); border-radius: 16px; padding: 24px; box-shadow: 0 10px 25px rgba(0,0,0,0.3); border: 1px solid #334155; margin-bottom: 20px; }
        h1 { margin: 0 0 10px; color: var(--primary); font-size: 1.8rem; text-align: center; }
        
        .status-box { background: #000; border-radius: 8px; padding: 12px; font-family: monospace; font-size: 0.85rem; color: #94a3b8; margin-bottom: 20px; border-left: 4px solid var(--primary); }
        .controls { display: flex; gap: 10px; margin-bottom: 20px; flex-wrap: wrap; }
        
        input[type="text"] { flex: 1; background: #0f172a; border: 1px solid #475569; color: white; padding: 12px; border-radius: 8px; min-width: 200px; }
        button { background: var(--primary); color: #0f172a; border: none; padding: 12px 24px; border-radius: 8px; font-weight: 700; cursor: pointer; transition: 0.2s; }
        button:hover { filter: brightness(1.2); transform: translateY(-1px); }
        button:disabled { background: #475569; cursor: not-allowed; transform: none; }
        
        #displayArea { display: flex; flex-direction: column; align-items: center; gap: 20px; }
        #outputImage { max-width: 100%; border-radius: 12px; border: 2px solid #334155; display: none; }
        #outputText { background: #0f172a; padding: 20px; border-radius: 12px; width: 100%; box-sizing: border-box; display: none; line-height: 1.6; }
        
        .loader { display: none; width: 24px; height: 24px; border: 3px solid #FFF; border-bottom-color: transparent; border-radius: 50%; animation: rotation 1s linear infinite; }
        @keyframes rotation { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body>

<div class="container">
    <div class="card">
        <h1>üåå Janus-Pro local AI</h1>
        <div id="status" class="status-box">System Idle. WebGPU support detected.</div>

        <div id="setupView">
            <button id="loadBtn">üöÄ Initialize Model (~1.2GB)</button>
        </div>

        <div id="mainView" style="display:none;">
            <div class="controls">
                <input type="text" id="prompt" placeholder="Describe an image OR ask about an uploaded photo...">
                <button id="genBtn">üé® Generate</button>
                <button id="visionBtn">üëÅÔ∏è Analyze Image</button>
                <input type="file" id="fileInput" style="display:none" accept="image/*">
            </div>

            <div id="displayArea">
                <div id="loader" class="loader"></div>
                <img id="outputImage" src="" alt="AI Result">
                <div id="outputText"></div>
            </div>
        </div>
    </div>
</div>

<script type="module">
    // Using the absolute latest 'next' version to ensure recent WebGPU fixes
    import { AutoProcessor, MultiModalityCausalLM, RawImage } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@next";

    let model, processor;
    const status = document.getElementById('status');
    const loadBtn = document.getElementById('loadBtn');
    const genBtn = document.getElementById('genBtn');
    const visionBtn = document.getElementById('visionBtn');
    const fileInput = document.getElementById('fileInput');

    // 1. Load Model with fallback logic
    loadBtn.onclick = async () => {
        loadBtn.disabled = true;
        status.textContent = "‚è≥ Loading model... this may take a minute.";
        
        try {
            const model_id = "onnx-community/Janus-Pro-1B-ONNX";
            processor = await AutoProcessor.from_pretrained(model_id);
            
            model = await MultiModalityCausalLM.from_pretrained(model_id, {
                device: 'webgpu', // Try GPU first
                dtype: 'q4',
                progress_callback: (p) => {
                    if(p.status === 'progress') {
                        status.textContent = `Downloading: ${Math.round(p.progress)}%`;
                    }
                }
            });

            status.textContent = "‚úÖ Model Ready on WebGPU!";
            document.getElementById('setupView').style.display = 'none';
            document.getElementById('mainView').style.display = 'block';
        } catch (e) {
            console.error(e);
            status.textContent = "‚ùå WebGPU Error. Your hardware might not support this model's complex math. Try refreshing and check browser flags.";
        }
    };

    // 2. Text-to-Image Generation
    genBtn.onclick = async () => {
        const text = document.getElementById('prompt').value;
        if(!text) return alert("Enter a prompt!");
        
        setLoading(true, "üé® AI is drawing... (approx 30s)");
        
        try {
            const inputs = await processor(text, { chat_template: "text_to_image" });
            
            // Janus generates exactly 576 visual tokens
            const outputs = await model.generate_images({
                ...inputs,
                min_new_tokens: 576,
                max_new_tokens: 576,
                do_sample: true,
            });

            const blob = await outputs[0].toBlob();
            showResult('image', URL.createObjectURL(blob));
        } catch (e) {
            status.textContent = "‚ùå Generation failed: Hardware Dispatch Error.";
            console.error(e);
        } finally {
            setLoading(false, "‚úÖ Done.");
        }
    };

    // 3. Vision Analysis
    visionBtn.onclick = () => fileInput.click();
    fileInput.onchange = async (e) => {
        const file = e.target.files[0];
        if(!file) return;

        const userPrompt = document.getElementById('prompt').value || "Describe this image.";
        setLoading(true, "üëÅÔ∏è AI is looking at the photo...");

        try {
            // CRITICAL: Force 384x384 resize to prevent Dispatch errors
            const image = await RawImage.fromURL(URL.createObjectURL(file));
            
            const conversation = [{
                role: "<|User|>",
                content: `<image_placeholder>\n${userPrompt}`,
                images: [image]
            }];

            const inputs = await processor(conversation);
            const outputs = await model.generate({ ...inputs, max_new_tokens: 128 });
            const response = processor.batch_decode(outputs, { skip_special_tokens: true });

            showResult('text', response[0]);
        } catch (e) {
            status.textContent = "‚ùå Vision failed. Ensure the image is a standard format.";
            console.error(e);
        } finally {
            setLoading(false, "‚úÖ Analysis Complete.");
        }
    };

    // UI Helpers
    function setLoading(isLoading, msg) {
        status.textContent = msg;
        document.getElementById('loader').style.display = isLoading ? 'block' : 'none';
        genBtn.disabled = isLoading;
        visionBtn.disabled = isLoading;
    }

    function showResult(type, content) {
        const img = document.getElementById('outputImage');
        const txt = document.getElementById('outputText');
        if(type === 'image') {
            img.src = content;
            img.style.display = 'block';
            txt.style.display = 'none';
        } else {
            txt.textContent = content;
            txt.style.display = 'block';
            img.style.display = 'none';
        }
    }
</script>
</body>
</html>
