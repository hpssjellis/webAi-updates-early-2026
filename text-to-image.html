<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Janus-Pro | Text-to-Image</title>
    <style>
        body { background: #080808; color: #e8e8e8; font-family: sans-serif; display: flex; flex-direction: column; align-items: center; padding: 20px; }
        .myCard { background: #101010; border: 1px solid #222; border-radius: 12px; padding: 25px; width: 100%; max-width: 600px; }
        #myOutputCanvas { width: 100%; border-radius: 8px; margin-top: 15px; display: none; background: #000; border: 1px solid #333; }
        .myBtn { width: 100%; padding: 12px; margin-top: 10px; cursor: pointer; border-radius: 6px; font-weight: bold; transition: opacity 0.2s; }
        .myBtn:disabled { opacity: 0.5; cursor: not-allowed; }
        #myStatus { font-size: 0.8rem; color: #888; margin-top: 10px; font-family: monospace; text-align: center; }
        textarea { border-radius: 6px; resize: none; }
    </style>
</head>
<body>

    <div class="myCard">
        <h2 style="color: #00ffcc; margin-top: 0;">‚ú¶ Janus-Pro Local Gen</h2>
        
        <div id="myLoadSection">
            <p style="font-size: 0.8rem; color: #666;">Downloads ~800MB - 1.2GB. WebGPU required.</p>
            <button class="myBtn" id="myLoadBtn" onclick="window.myInitModel()" style="background: transparent; border: 1px solid #00ffcc; color: #00ffcc;">‚ö° Load Model</button>
        </div>

        <div id="myGenSection" style="display: none;">
            <textarea id="myPromptInput" style="width: 100%; height: 80px; background: #000; color: #fff; border: 1px solid #333; padding: 10px; box-sizing: border-box;" placeholder="A beautiful oil painting of a futuristic city..."></textarea>
            
            <button class="myBtn" id="myGenBtn" onclick="window.myGenerateImage()" style="background: #00ffcc; border: none; color: #000;">‚ú¶ Generate Image</button>
            
            <div id="myTokenProgress" style="height: 6px; background: #222; margin-top: 15px; display: none; border-radius: 3px; overflow: hidden;">
                <div id="myTokenBar" style="height: 100%; background: #00ffcc; width: 0%; transition: width 0.1s;"></div>
            </div>
        </div>

        <canvas id="myOutputCanvas"></canvas>
        <div id="myStatus">Ready to load.</div>
    </div>


<script type="module">

// FIX 1: RawImage is not needed for T2I generation ‚Äî removed from import.
// MultiModalityCausalLM is the correct class for Janus in transformers.js.
import { AutoProcessor, MultiModalityCausalLM, env } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@4.0.0-next.4";

env.allowLocalModels = false;

let myModel = null;
let myProcessor = null;
const myStatus = document.getElementById('myStatus');
const myCanvas = document.getElementById('myOutputCanvas');

window.myInitModel = async function() {
    const myBtn = document.getElementById('myLoadBtn');
    myBtn.disabled = true;
    myStatus.innerText = "‚è≥ Initializing WebGPU & Loading Model...";

    try {
        const myModelId = "onnx-community/Janus-Pro-1B-ONNX";

        myProcessor = await AutoProcessor.from_pretrained(myModelId);

        myModel = await MultiModalityCausalLM.from_pretrained(myModelId, {
            // FIX 2: device must be a per-submodel map, NOT a single string.
            // prepare_inputs_embeds has a known WebGPU bug; keep it on "wasm".
            // All other submodels can use "webgpu" for acceleration.
            device: {
                prepare_inputs_embeds: "wasm",
                language_model: "webgpu",
                lm_head: "webgpu",
                gen_head: "webgpu",
                gen_img_embeds: "webgpu",
                image_decode: "webgpu",
            },
            dtype: {
                prepare_inputs_embeds: "fp32",  // wasm submodel ‚Äî fp32 is safe
                language_model: "q4",
                lm_head: "fp16",
                gen_head: "fp16",
                gen_img_embeds: "fp16",
                image_decode: "fp32",           // Essential for decode quality
            }
        });

        myStatus.innerText = "üü¢ Model Ready!";
        document.getElementById('myLoadSection').style.display = 'none';
        document.getElementById('myGenSection').style.display = 'block';
    } catch (myErr) {
        console.error(myErr);
        myStatus.innerText = "‚ùå Error: " + myErr.message;
        myBtn.disabled = false;
    }
};

window.myGenerateImage = async function() {
    const myPrompt = document.getElementById('myPromptInput').value;
    const myGenBtn = document.getElementById('myGenBtn');
    const myBar = document.getElementById('myTokenBar');
    const myWrap = document.getElementById('myTokenProgress');

    if (!myPrompt) return alert("Please enter a prompt");

    myGenBtn.disabled = true;
    myCanvas.style.display = 'none';
    myWrap.style.display = 'block';
    myBar.style.width = "0%";

    try {
        // FIX 3: conversation role must be "User" (capital U), not "user".
        // This is Janus-specific ‚Äî it uses its own chat format, not ChatML.
        const myMessages = [{ role: "User", content: myPrompt }];
        const myInputs = await myProcessor(myMessages, { chat_template: "text_to_image" });

        // FIX 4: Use processor.num_image_tokens (the correct property) instead
        // of the magic number 576. This ensures compatibility across model variants.
        const myNumTokens = myProcessor.num_image_tokens;
        myStatus.innerText = `üé® Generating ${myNumTokens} tokens...`;

        // FIX 5: Use model.generate_images() instead of model.generate().
        // For Janus T2I, generate_images() handles the full image generation
        // pipeline and returns RawImage objects directly ‚Äî no manual slicing,
        // no manual decode_image() call, no output_ids indexing needed.
        // model.generate() is for text generation (image understanding tasks).
        const myOutputs = await myModel.generate_images({
            ...myInputs,
            min_new_tokens: myNumTokens,
            max_new_tokens: myNumTokens,
            do_sample: true,
            temperature: 1.0,
            // FIX 6: The progress callback for generate/generate_images is named
            // `callback_function` and receives (output_ids_batch) at each step.
            // We track count of new tokens by subtracting the input length.
            callback_function: (output_ids) => {
                const promptLen = myInputs.input_ids.dims.at(-1);
                const currentTokens = output_ids[0].length - promptLen;
                const myPct = Math.min((currentTokens / myNumTokens) * 100, 100);
                myBar.style.width = myPct + "%";
            }
        });

        myStatus.innerText = "‚ú® Rendering image...";

        // FIX 7: generate_images() returns an array of RawImage objects.
        // Use .toCanvas() to render the first result directly onto our canvas.
        // The old code called model.decode_image() manually ‚Äî that step is
        // now done internally by generate_images().
        await myOutputs[0].toCanvas(myCanvas);

        myCanvas.style.display = 'block';
        myStatus.innerText = "‚úÖ Done!";

    } catch (myErr) {
        console.error(myErr);
        myStatus.innerText = "‚ùå Gen Error: " + myErr.message;
    } finally {
        myGenBtn.disabled = false;
        myWrap.style.display = 'none';
    }
};
</script>
</body>
</html>
