<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Real-Time Transcription (Whisper)</title>
</head>
<body style="font-family: sans-serif; padding: 20px; text-align: center; background: #111; color: white;">
    <h1>Real-Time Transcription (Whisper)</h1>
    <button id="myStartBtn" style="padding: 15px 30px; font-size: 1.2rem; cursor: pointer; border-radius: 8px; border: none; background: #007bff; color: white;">
        Start Listening
    </button>
    <div id="myTranscript" style="margin-top: 30px; border: 1px solid #444; padding: 20px; min-height: 100px; text-align: left; background: #222; border-radius: 8px;">
        Transcribed text will appear here...
    </div>

    <script type="module">
        import { pipeline } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@4.0.0-next.4';

        let myTranscriber;
        let myIsRecording = false;

        async function myStartAudio() {
            if (myIsRecording) return;
            myIsRecording = true;

            const myStatusElement = document.getElementById('myTranscript');
            const myBtn = document.getElementById('myStartBtn');
            myBtn.disabled = true;
            myStatusElement.innerText = "Loading Whisper model...";

            try {
                // FIX 1: Model ID is correct (onnx-community/whisper-tiny.en).
                // FIX 2: dtype must be a per-submodel map for Whisper, NOT a single string.
                // Whisper has two submodels: encoder_model and decoder_model_merged.
                // The safe and proven WebGPU dtype combo is encoder=fp32, decoder=q4.
                // A single dtype: 'fp16' applied to the decoder produces broken/garbled output.
                myTranscriber = await pipeline(
                    'automatic-speech-recognition',
                    'onnx-community/whisper-tiny.en',
                    {
                        device: 'webgpu',
                        dtype: {
                            encoder_model: 'fp32',
                            decoder_model_merged: 'q4',
                        },
                    }
                );

                myStatusElement.innerText = "Model loaded. Requesting microphone...";

                const myStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                // FIX 3: createScriptProcessor is deprecated and removed in many browsers.
                // The modern replacement is AudioWorkletProcessor. However, for a simple
                // real-time accumulation approach, the cleanest cross-browser solution is
                // MediaRecorder â€” capture fixed-length chunks as Blobs, decode them via
                // AudioContext.decodeAudioData(), then pass Float32Array to the pipeline.
                // This avoids the deprecated API and the complex worklet setup entirely.
                const myAudioContext = new AudioContext({ sampleRate: 16000 });

                // FIX 4: The pipeline expects the input as an OBJECT with shape:
                //   { raw: Float32Array, sampling_rate: 16000 }
                // NOT a bare Float32Array. Passing a raw array causes the pipeline to
                // assume an unknown/wrong sample rate and produces garbage transcriptions.

                // We use MediaRecorder to capture 3-second chunks for transcription.
                // This is more reliable than processing 4096-sample raw buffers directly,
                // which are too short (~0.25s) for Whisper to produce meaningful output.
                const CHUNK_DURATION_MS = 3000;
                const myRecorder = new MediaRecorder(myStream);
                let myChunks = [];

                myRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) myChunks.push(e.data);
                };

                myRecorder.onstop = async () => {
                    const myBlob = new Blob(myChunks, { type: myRecorder.mimeType });
                    myChunks = [];

                    try {
                        // Decode the audio blob into a Float32Array at 16kHz
                        const myArrayBuffer = await myBlob.arrayBuffer();
                        const myDecodedAudio = await myAudioContext.decodeAudioData(myArrayBuffer);

                        // Get mono channel data (channel 0)
                        const myFloat32 = myDecodedAudio.getChannelData(0);

                        // FIX 4 (continued): Pass as { raw, sampling_rate } object
                        const myResult = await myTranscriber(
                            { raw: myFloat32, sampling_rate: 16000 }
                        );

                        if (myResult && myResult.text && myResult.text.trim()) {
                            // Append each chunk's transcription rather than replacing it
                            myStatusElement.innerText += myResult.text;
                        }
                    } catch (myDecodeErr) {
                        console.warn("Chunk decode error:", myDecodeErr);
                    }

                    // Restart recording the next chunk if still active
                    if (myIsRecording) {
                        myRecorder.start();
                        setTimeout(() => {
                            if (myRecorder.state === 'recording') myRecorder.stop();
                        }, CHUNK_DURATION_MS);
                    }
                };

                // FIX 5: Clear the status message and start recording
                myStatusElement.innerText = "";
                myBtn.textContent = "Listening... ðŸ”´";

                // Start the first chunk
                myRecorder.start();
                setTimeout(() => {
                    if (myRecorder.state === 'recording') myRecorder.stop();
                }, CHUNK_DURATION_MS);

            } catch (myErr) {
                myStatusElement.innerText = "Error: " + myErr.message;
                console.error(myErr);
                myIsRecording = false;
                myBtn.disabled = false;
            }
        }

        document.getElementById('myStartBtn').onclick = myStartAudio;
    </script>
</body>
</html>
