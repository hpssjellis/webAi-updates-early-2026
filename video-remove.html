<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MODNet ‚Äî Live Video Background Removal</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body { background: #0a0a0a; color: #eee; font-family: sans-serif; display: flex; flex-direction: column; align-items: center; padding: 20px; min-height: 100vh; }
        h1 { color: #00ffcc; margin-bottom: 6px; font-size: 1.4rem; }
        p.sub { color: #555; font-size: 0.8rem; margin-bottom: 20px; }
        .canvases { display: flex; gap: 16px; flex-wrap: wrap; justify-content: center; }
        .panel { text-align: center; }
        .panel span { display: block; font-size: 0.75rem; color: #666; margin-bottom: 6px; }
        video { display: none; }
        canvas { width: 320px; height: 240px; border: 1px solid #333; border-radius: 8px; background: #111; display: block; }
        #myBgCanvas {
            background-image: repeating-conic-gradient(#1a1a1a 0% 25%, #2a2a2a 0% 50%);
            background-size: 16px 16px;
        }
        .controls { margin-top: 20px; display: flex; gap: 10px; flex-wrap: wrap; justify-content: center; }
        button { padding: 10px 24px; font-weight: bold; border: none; border-radius: 6px; cursor: pointer; font-size: 0.9rem; }
        button:disabled { opacity: 0.4; cursor: not-allowed; }
        #myLoadBtn    { background: #00ffcc; color: #000; }
        #myStartBtn   { background: #ff0077; color: #fff; }
        #myStopBtn    { background: #333;    color: #eee; }
        #myRecordBtn  { background: #ff6600; color: #fff; }
        #myStopRecBtn { background: #333;    color: #eee; }
        #myStatus { margin-top: 14px; font-family: monospace; font-size: 0.78rem; color: #666; text-align: center; max-width: 500px; }
        #myDownloadArea { margin-top: 14px; }
        #myDownloadArea a { color: #00ffcc; font-size: 0.85rem; text-decoration: none; border: 1px solid #00ffcc; padding: 8px 18px; border-radius: 6px; }
        #myDownloadArea a:hover { background: #00ffcc22; }
    </style>
</head>
<body>

    <h1>‚ú¶ MODNet ‚Äî Live Video BG Removal</h1>
    <p class="sub">WebGPU ¬∑ Runs 100% locally ¬∑ No data leaves your device</p>

    <div class="canvases">
        <div class="panel"><span>Camera Feed</span><canvas id="mySrcCanvas" width="640" height="480"></canvas></div>
        <div class="panel"><span>Background Removed</span><canvas id="myBgCanvas" width="640" height="480"></canvas></div>
    </div>

    <!-- Hidden video ‚Äî pixel source only, never shown -->
    <video id="myVideo" autoplay playsinline muted></video>

    <div class="controls">
        <button id="myLoadBtn" disabled>‚ö° Load MODNet</button>
        <button id="myStartBtn"   disabled>‚ñ∂ Start</button>
        <button id="myStopBtn"    disabled>‚èπ Stop</button>
        <button id="myRecordBtn"  disabled>‚è∫ Record</button>
        <button id="myStopRecBtn" disabled>‚èπ Stop Recording</button>
    </div>

    <div id="myDownloadArea"></div>
    <div id="myStatus">Requesting camera...</div>

    <script type="module">
        import { AutoModel, AutoProcessor, RawImage, env }
            from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@4.0.0-next.4";

        env.allowLocalModels = false;

        // ‚îÄ‚îÄ DOM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        const myVideo      = document.getElementById('myVideo');
        const mySrcCanvas  = document.getElementById('mySrcCanvas');
        const myBgCanvas   = document.getElementById('myBgCanvas');
        // willReadFrequently speeds up the repeated getImageData calls in the mask composite
        const mySrcCtx     = mySrcCanvas.getContext('2d', { willReadFrequently: true });
        const myBgCtx      = myBgCanvas.getContext('2d',  { willReadFrequently: true });
        const myStatus     = document.getElementById('myStatus');
        const myLoadBtn    = document.getElementById('myLoadBtn');
        const myStartBtn   = document.getElementById('myStartBtn');
        const myStopBtn    = document.getElementById('myStopBtn');
        const myRecordBtn  = document.getElementById('myRecordBtn');
        const myStopRecBtn = document.getElementById('myStopRecBtn');
        const myDlArea     = document.getElementById('myDownloadArea');

        // ‚îÄ‚îÄ State ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        let myModel      = null;
        let myProcessor  = null;
        let myRunning    = false;
        let myInferring  = false;   // guard: only one inference in-flight at a time
        let myRecorder   = null;
        let myChunks     = [];

        // ‚îÄ‚îÄ Camera ‚Äî start immediately, exactly like the working YOLO code ‚îÄ‚îÄ‚îÄ‚îÄ
        // Key insight from YOLO: draw the video element inside requestAnimationFrame
        // directly onto the canvas each frame. No persistent transform. No IIFE.
        // Mirror per-frame by saving/restoring context state around each drawImage.
        async function myStartCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480, facingMode: 'user' }
                });
                myVideo.srcObject = stream;
                await new Promise(r => myVideo.onloadedmetadata = () => {
                    // Resize canvases to match actual camera resolution
                    const W = myVideo.videoWidth  || 640;
                    const H = myVideo.videoHeight || 480;
                    mySrcCanvas.width  = myBgCanvas.width  = W;
                    mySrcCanvas.height = myBgCanvas.height = H;
                    r();
                });
                myStatus.textContent = 'Camera ready ‚Äî click "Load MODNet" to continue.';
                myLoadBtn.disabled = false;

                // Continuous 60fps preview loop ‚Äî mirrors video onto src canvas each frame.
                // Using save/restore + per-frame transform (not a persistent one) so the
                // canvas context is never left in a corrupted state between frames.
                function myPreviewLoop() {
                    mySrcCtx.save();
                    mySrcCtx.translate(mySrcCanvas.width, 0);
                    mySrcCtx.scale(-1, 1);
                    mySrcCtx.drawImage(myVideo, 0, 0, mySrcCanvas.width, mySrcCanvas.height);
                    mySrcCtx.restore();
                    requestAnimationFrame(myPreviewLoop);
                }
                myPreviewLoop();

            } catch (e) {
                myStatus.textContent = '‚ùå Camera denied: ' + e.message;
            }
        }

        myStartCamera();

        // ‚îÄ‚îÄ Model load ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        myLoadBtn.onclick = async () => {
            myLoadBtn.disabled = true;
            myStatus.textContent = '‚è≥ Loading MODNet...';
            console.log('[MODNet] Loading model...');

            try {
                // dtype: 'fp32' is required ‚Äî fp16 produces corrupt mask output on WebGPU
                myModel = await AutoModel.from_pretrained('Xenova/modnet', {
                    device: 'webgpu',
                    dtype: 'fp32',
                    progress_callback: (p) => {
                        if (p.status === 'initiate') {
                            myStatus.textContent = `Fetching: ${p.file}`;
                        } else if (p.status === 'progress' && p.total) {
                            const pct = Math.round(p.progress);
                            const mb  = (p.loaded / 1024 / 1024).toFixed(1);
                            const tot = (p.total  / 1024 / 1024).toFixed(1);
                            myStatus.textContent = `‚Üì ${p.file}  ${mb} / ${tot} MB  (${pct}%)`;
                        } else if (p.status === 'done') {
                            myStatus.textContent = `‚úî Loaded: ${p.file}`;
                        }
                    },
                });

                myProcessor = await AutoProcessor.from_pretrained('Xenova/modnet');

                myStatus.textContent = 'üü¢ Ready ‚Äî press Start!';
                myStartBtn.disabled = false;
                myLoadBtn.style.display = 'none';

            } catch (e) {
                myStatus.textContent = '‚ùå Load failed: ' + e.message;
                console.error('[MODNet]', e);
                myLoadBtn.disabled = false;
            }
        };

        // ‚îÄ‚îÄ Inference ‚Äî fire-and-forget pattern from YOLO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        // Never blocks the preview loop. Sets myInferring guard so calls don't stack.
        // The src canvas is always current (drawn by myPreviewLoop at 60fps),
        // so we snapshot it at the moment fireInference() is called.
        function myFireInference() {
            if (myInferring || !myModel || !myRunning) return;
            myInferring = true;

            // Snapshot the current mirrored frame from the src canvas
            const myFrame = RawImage.fromCanvas(mySrcCanvas);

            myProcessor(myFrame)
                .then(({ pixel_values }) => myModel({ input: pixel_values }))
                .then(async ({ output }) => {
                    // output[0] is a float32 [0-1] alpha matte tensor
                    const myMask = await RawImage
                        .fromTensor(output[0].mul(255).to('uint8'))
                        .resize(mySrcCanvas.width, mySrcCanvas.height);

                    // Composite: copy the current src frame, then apply mask as alpha
                    myBgCtx.clearRect(0, 0, myBgCanvas.width, myBgCanvas.height);
                    myBgCtx.drawImage(mySrcCanvas, 0, 0);

                    const myImgData  = myBgCtx.getImageData(0, 0, myBgCanvas.width, myBgCanvas.height);
                    const myPixels   = myImgData.data;
                    const myMaskData = myMask.data;   // 1-channel Uint8Array

                    for (let i = 0; i < myMaskData.length; i++) {
                        myPixels[i * 4 + 3] = myMaskData[i];
                    }
                    myBgCtx.putImageData(myImgData, 0, 0);
                    myStatus.textContent = 'üü¢ Running ‚Äî WebGPU active';
                })
                .catch(e => {
                    console.error('[MODNet] Frame error:', e);
                    myStatus.textContent = '‚ö†Ô∏è Frame error (retrying)';
                })
                .finally(() => {
                    myInferring = false;
                    // Tail-call: schedule next inference immediately after this one finishes,
                    // but only if still running ‚Äî prevents unbounded queue buildup
                    if (myRunning) setTimeout(myFireInference, 0);
                });
        }

        // ‚îÄ‚îÄ Inference controls ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        myStartBtn.onclick = () => {
            myRunning = true;
            myStartBtn.disabled  = true;
            myStopBtn.disabled   = false;
            myRecordBtn.disabled = false;
            myFireInference();
        };

        myStopBtn.onclick = () => {
            myRunning = false;
            myStartBtn.disabled  = false;
            myStopBtn.disabled   = true;
            myRecordBtn.disabled = true;
            if (myRecorder && myRecorder.state === 'recording') myStopRecBtn.click();
            myStatus.textContent = '‚è∏ Paused.';
        };

        // ‚îÄ‚îÄ Recording ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        myRecordBtn.onclick = () => {
            myChunks = [];
            myDlArea.innerHTML = '';

            const myStream = myBgCanvas.captureStream(30);
            myRecorder = new MediaRecorder(myStream, {
                mimeType: MediaRecorder.isTypeSupported('video/webm;codecs=vp9')
                    ? 'video/webm;codecs=vp9' : 'video/webm',
            });

            myRecorder.ondataavailable = e => { if (e.data.size > 0) myChunks.push(e.data); };
            myRecorder.onstop = () => {
                const myBlob   = new Blob(myChunks, { type: 'video/webm' });
                const myUrl    = URL.createObjectURL(myBlob);
                const myLink   = document.createElement('a');
                myLink.href      = myUrl;
                myLink.download  = `modnet-${Date.now()}.webm`;
                myLink.textContent = '‚¨áÔ∏è Download Recorded Video (.webm)';
                myDlArea.appendChild(myLink);
                myStatus.textContent = '‚úÖ Recording saved ‚Äî click the link to download.';
            };

            myRecorder.start();
            myRecordBtn.disabled  = true;
            myStopRecBtn.disabled = false;
            myStatus.textContent  = '‚è∫ Recording...';
        };

        myStopRecBtn.onclick = () => {
            if (myRecorder && myRecorder.state === 'recording') myRecorder.stop();
            myRecordBtn.disabled  = false;
            myStopRecBtn.disabled = true;
        };
    </script>
</body>
</html>
