<body style="background: #111; color: #fff; font-family: sans-serif; display: flex; flex-direction: column; align-items: center; padding: 20px;">

    <h2 style="color: #ff0077;">‚úÇÔ∏è AI Background Remover</h2>

    <div style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
        <div style="text-align: center;">
            <p style="color: #888;">Camera Input</p>
            <video id="myCam" autoplay playsinline muted style="width: 320px; height: 240px; background: #000; border-radius: 8px; transform: scaleX(-1);"></video>
        </div>

        <div style="text-align: center;">
            <p style="color: #888;">Transparent Result</p>
            <canvas id="myOutputCanvas" width="320" height="240" style="background-image: repeating-conic-gradient(#222 0% 25%, #333 0% 50%); background-position: 0 0, 10px 10px; background-size: 20px 20px; border: 2px solid #ff0077; border-radius: 8px;"></canvas>
        </div>
    </div>

    <div style="margin-top: 20px; text-align: center;">
        <button id="myActionBtn" style="padding: 12px 30px; background: #ff0077; border: none; border-radius: 5px; cursor: pointer; font-weight: bold; font-size: 1rem; color: white;">
            ‚ú® Start Background Removal
        </button>
        <div id="myStatus" style="margin-top: 10px; font-family: monospace; font-size: 0.8rem; color: #888;">Click to load model (approx. 170MB)</div>
    </div>

    <script type="module">
        import { pipeline, env } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.0.0-alpha.19";

        // Configuration
        env.allowLocalModels = false;
        
        let myRemoverPipe = null;
        let isProcessing = false;
        const myCam = document.getElementById("myCam");
        const myOutputCanvas = document.getElementById("myOutputCanvas");
        const myCtx = myOutputCanvas.getContext("2d", { willReadFrequently: true });
        const myStatus = document.getElementById("myStatus");

        async function mySetupCamera() {
            try {
                const myStream = await navigator.mediaDevices.getUserMedia({ video: { width: 320, height: 240 } });
                myCam.srcObject = myStream;
                return new Promise(resolve => myCam.onloadedmetadata = () => resolve());
            } catch (e) {
                throw new Error("Camera access denied.");
            }
        }

        async function myProcessLoop() {
            if (!myRemoverPipe) return;

            try {
                // 1. Capture current frame from video to an offscreen image
                const bitmap = await createImageBitmap(myCam);
                
                // 2. Run the model on the bitmap
                const myOutput = await myRemoverPipe(bitmap);
                
                // 3. Get the mask (which is returned as a canvas/image by the new API)
                const maskCanvas = await myOutput.mask.toCanvas();

                // 4. Draw to output canvas
                myCtx.clearRect(0, 0, 320, 240);
                
                // Mirror the drawing
                myCtx.save();
                myCtx.translate(320, 0);
                myCtx.scale(-1, 1);
                
                // Draw original video frame
                myCtx.drawImage(myCam, 0, 0, 320, 240);
                
                // Use 'destination-in' to apply the mask as a transparency layer
                myCtx.globalCompositeOperation = 'destination-in';
                myCtx.drawImage(maskCanvas, 0, 0, 320, 240);
                
                myCtx.restore();
                myCtx.globalCompositeOperation = 'source-over'; // Reset

                myStatus.innerText = "Running... ‚úÖ";
            } catch (myErr) {
                console.error("Loop Error:", myErr);
            }

            requestAnimationFrame(myProcessLoop);
        }

        async function myInit() {
            if (myRemoverPipe) return; 
            
            myStatus.innerText = "‚è≥ Loading Model (this may take a minute)...";
            try {
                await mySetupCamera();
                
                // Using image-segmentation task
                myRemoverPipe = await pipeline("image-segmentation", "briaai/RMBG-1.4", {
                    device: "webgpu", // Use "wasm" if you don't have a dedicated GPU
                });

                myStatus.innerText = "üü¢ Model Ready!";
                myProcessLoop();
            } catch (myErr) {
                myStatus.innerText = "‚ùå Error: " + myErr.message;
                console.error(myErr);
            }
        }

        document.getElementById('myActionBtn').onclick = myInit;
    </script>
</body>
