<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>v4 AI Background Remover</title>
</head>
<body style="background: #111; color: #fff; font-family: sans-serif; display: flex; flex-direction: column; align-items: center; padding: 20px;">

    <h2 style="color: #ff0077;">‚úÇÔ∏è Transformers.js v4 Background Remover</h2>

    <div style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
        <div style="text-align: center;">
            <p style="color: #888;">Camera Input</p>
            <video id="myCam" autoplay playsinline muted style="width: 320px; height: 240px; background: #000; border-radius: 8px; transform: scaleX(-1);"></video>
        </div>

        <div style="text-align: center;">
            <p style="color: #888;">Transparent Result</p>
            <canvas id="myOutputCanvas" width="320" height="240" style="background-image: repeating-conic-gradient(#222 0% 25%, #333 0% 50%); background-position: 0 0, 10px 10px; background-size: 20px 20px; border: 2px solid #ff0077; border-radius: 8px;"></canvas>
        </div>
    </div>

    <div style="margin-top: 20px; text-align: center;">
        <button id="myActionBtn" style="padding: 12px 30px; background: #ff0077; border: none; border-radius: 5px; cursor: pointer; font-weight: bold; font-size: 1rem; color: white;">
            ‚ú® Start Background Removal
        </button>
        <div id="myStatus" style="margin-top: 10px; font-family: monospace; font-size: 0.8rem; color: #888;">Click to load v4 model (WebGPU)</div>
    </div>

    <script type="module">
        // Updated to the v4 next CDN
        import { pipeline, env } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@4.0.0-next.4";

        // Configuration for v4
        env.allowLocalModels = false;
        
        let myRemoverPipe = null;
        const myCam = document.getElementById("myCam");
        const myOutputCanvas = document.getElementById("myOutputCanvas");
        const myCtx = myOutputCanvas.getContext("2d", { willReadFrequently: true });
        const myStatus = document.getElementById("myStatus");

        async function mySetupCamera() {
            try {
                const myStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 320, height: 240 } 
                });
                myCam.srcObject = myStream;
                return new Promise(resolve => myCam.onloadedmetadata = () => resolve());
            } catch (e) {
                throw new Error("Camera access denied. Please allow camera permissions.");
            }
        }

        async function myProcessLoop() {
            if (!myRemoverPipe) return;

            try {
                // 1. Capture current frame
                const canvas = document.createElement('canvas');
                canvas.width = myCam.videoWidth;
                canvas.height = myCam.videoHeight;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(myCam, 0, 0);
                
                // 2. Run the model
                // In v4, we can pass the canvas directly
                const result = await myRemoverPipe(canvas);
                
                // 3. Extract the mask
                // The RMBG-1.4 model returns a mask in the 'mask' property
                const mask = await result.mask.toCanvas();

                // 4. Draw to output
                myCtx.clearRect(0, 0, myOutputCanvas.width, myOutputCanvas.height);
                
                myCtx.save();
                // Mirror the output to match the camera preview
                myCtx.translate(myOutputCanvas.width, 0);
                myCtx.scale(-1, 1);
                
                // Draw original frame
                myCtx.drawImage(myCam, 0, 0, 320, 240);
                
                // Composite the mask
                myCtx.globalCompositeOperation = 'destination-in';
                myCtx.drawImage(mask, 0, 0, 320, 240);
                
                myCtx.restore();

                myStatus.innerText = "Running on WebGPU ‚úÖ";
            } catch (myErr) {
                console.error("Processing Error:", myErr);
            }

            // Keep the loop going
            requestAnimationFrame(myProcessLoop);
        }

        async function myInit() {
            if (myRemoverPipe) return; 
            
            myStatus.innerText = "‚è≥ Initializing WebGPU & Loading Model...";
            
            try {
                await mySetupCamera();
                
                // Load the v4 pipeline
                myRemoverPipe = await pipeline("image-segmentation", "briaai/RMBG-1.4", {
                    device: "webgpu", // v4's standout feature
                });

                myStatus.innerText = "üü¢ WebGPU Active!";
                myProcessLoop();
            } catch (myErr) {
                myStatus.innerText = "‚ùå Error: " + myErr.message;
                console.error(myErr);
                
                // Fallback attempt with WASM if WebGPU fails
                if (myErr.message.includes('WebGPU')) {
                    myStatus.innerText = "WebGPU failed. Trying WASM fallback...";
                    myRemoverPipe = await pipeline("image-segmentation", "briaai/RMBG-1.4", {
                        device: "wasm",
                    });
                    myProcessLoop();
                }
            }
        }

        document.getElementById('myActionBtn').onclick = myInit;
    </script>
</body>
</html>
