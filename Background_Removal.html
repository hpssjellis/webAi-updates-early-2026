<body style="background: #111; color: #fff; font-family: sans-serif; display: flex; flex-direction: column; align-items: center; padding: 20px;">

    <h2 style="color: #ff0077;">‚úÇÔ∏è AI Background Remover</h2>

    <div style="display: flex; gap: 20px; flex-wrap: wrap; justify-content: center;">
        <div style="text-align: center;">
            <p style="color: #888;">Camera Input</p>
            <video id="myCam" autoplay playsinline muted style="width: 320px; height: 240px; background: #000; border-radius: 8px; transform: scaleX(-1);"></video>
        </div>

        <div style="text-align: center;">
            <p style="color: #888;">Transparent Result</p>
            <canvas id="myOutputCanvas" width="320" height="240" style="background-image: linear-gradient(45deg, #222 25%, transparent 25%), linear-gradient(-45deg, #222 25%, transparent 25%), linear-gradient(45deg, transparent 75%, #222 75%), linear-gradient(-45deg, transparent 75%, #222 75%); background-size: 20px 20px; border: 2px solid #ff0077; border-radius: 8px;"></canvas>
        </div>
    </div>

    <div style="margin-top: 20px; text-align: center;">
        <button id="myActionBtn" style="padding: 12px 30px; background: #ff0077; border: none; border-radius: 5px; cursor: pointer; font-weight: bold; font-size: 1rem; color: white;">
            ‚ú® Start Background Removal
        </button>
        <div id="myStatus" style="margin-top: 10px; font-family: monospace; font-size: 0.8rem; color: #888;">Click to load model</div>
    </div>

    <script type="module">
        import { pipeline, env, RawImage } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@4.0.0-next.4";

        env.allowLocalModels = false;
        
        let myRemoverPipe = null;
        const myCam = document.getElementById("myCam");
        const myOutputCanvas = document.getElementById("myOutputCanvas");
        const myCtx = myOutputCanvas.getContext("2d", { willReadFrequently: true });
        const myStatus = document.getElementById("myStatus");

        async function mySetupCamera() {
            const myStream = await navigator.mediaDevices.getUserMedia({ video: { width: 320, height: 240 } });
            myCam.srcObject = myStream;
            return new Promise(resolve => myCam.onloadedmetadata = () => {
                myCam.play();
                resolve();
            });
        }

        async function myProcessLoop() {
            if (!myRemoverPipe) return;

            try {
                // FIX: Pass the video ELEMENT directly to the pipeline
                const myOutput = await myRemoverPipe(myCam);
                
                // The mask comes back as a RawImage in the first element
                const myMask = myOutput[0].mask; 
                
                // Resize mask to match our display canvas and get the raw bytes
                const myResizedMask = await myMask.resize(320, 240);
                const myMaskBytes = myResizedMask.data; 

                // Draw the current camera frame to our canvas
                myCtx.clearRect(0, 0, 320, 240);
                myCtx.save();
                // Mirror the output to match the mirrored camera input
                myCtx.translate(320, 0);
                myCtx.scale(-1, 1);
                myCtx.drawImage(myCam, 0, 0, 320, 240);
                myCtx.restore();

                // Manipulate the Alpha channel (transparency)
                const myImgData = myCtx.getImageData(0, 0, 320, 240);
                for (let i = 0; i < myMaskBytes.length; ++i) {
                    // i is the pixel index. Pixel i's alpha is at index (i * 4) + 3
                    myImgData.data[i * 4 + 3] = myMaskBytes[i]; 
                }

                myCtx.putImageData(myImgData, 0, 0);
                myStatus.innerText = "Running...";
            } catch (myErr) {
                console.error(myErr);
            }

            // Keep the loop going
            requestAnimationFrame(myProcessLoop);
        }

        async function myInit() {
            if (myRemoverPipe) return; // Prevent double clicks
            
            myStatus.innerText = "‚è≥ Loading RMBG-1.4 (WebGPU)...";
            try {
                await mySetupCamera();
                
                myRemoverPipe = await pipeline("image-segmentation", "briaai/RMBG-1.4", {
                    device: "webgpu",
                    dtype: "fp16" 
                });

                myStatus.innerText = "üü¢ Model Ready!";
                myProcessLoop();
            } catch (myErr) {
                myStatus.innerText = "‚ùå Error: " + myErr.message;
            }
        }

        // Static link to function
        document.getElementById('myActionBtn').onclick = myInit;
    </script>
</body>
